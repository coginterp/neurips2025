<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on </title>
    <link>http://localhost:1313/neurips2025/</link>
    <description>Recent content in Home on </description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/neurips2025/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Accepted Papers</title>
      <link>http://localhost:1313/neurips2025/accepted-papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/accepted-papers/</guid>
      <description>&lt;h1 id=&#34;accepted-papers&#34;&gt;Accepted Papers&lt;/h1&gt;&#xA;&lt;div&gt;&#xA;&lt;b&gt;Spotlight Talks&lt;/b&gt;&#xA;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=8BOs9HYyFe&#34;&gt;&#34;Interpretable Hybrid Neural-Cognitive Models Discover Cognitive Strategies Underlying Flexible Reversal Learning&#34;&lt;/a&gt;. Chonghao Cai, Liyuan Li, Yifei Cao, Maria K Eckstein.&#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=tqp9Cp8quj&#34;&gt;&#34;Mechanisms of Symbol Processing in Transformers&#34;&lt;/a&gt;. Paul Smolensky, Roland Fernandez, Zhenghao Zhou, Mattia Opper, Adam Davies, Jianfeng Gao.&#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=kedJDTAoAd&#34;&gt;&#34;Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression&#34;&lt;/a&gt;. Nathaniel Imel, Noga Zaslavsky.&#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=foAB8xC74C&#34;&gt;&#34;Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs&#34;&lt;/a&gt;. Sonia Krishna Murthy, Rosie Zhao, Jennifer Hu, Sham M. Kakade, Markus Wulfmeier, Peng Qian, Tomer Ullman.&#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;b&gt;Posters&lt;/b&gt;&#xA;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=KTjmPDmHkQ&#34;&gt;&#34;Cognitive Behavior Modeling via Activation Steering&#34;&lt;/a&gt;. Anthony Kuang, Ahmed Ismail, Ayo Akinkugbe, Kevin Zhu, Sean O&#39;Brien. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=2ZfC2cErzZ&#34;&gt;&#34;Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition&#34;&lt;/a&gt;. Dong Liu, Yanxuan Yu. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=4RYAkpAbee&#34;&gt;&#34;Don’t Think of the White Bear: Ironic Negation in Transformer Models under Cognitive Load&#34;&lt;/a&gt;. Logan Mann, Nayan Saxena, Sarah Tandon, Chenhao Sun, Savar Toteja, Kevin Zhu. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=cbrdNqtd9y&#34;&gt;&#34;A Control-Theoretic Account of Cognitive Effort in Language Models&#34;&lt;/a&gt;. Pranjal Garg. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=7Abkcg2P6V&#34;&gt;&#34;On the Role of Pretraining in Domain Adaptation in an Infant-Inspired Distribution Shift Task&#34;&lt;/a&gt;. Deepayan Sanyal, Joel Phillips Michelson, Maithilee Kunda. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=pkKO5Kph3o&#34;&gt;&#34;When Researchers Say Mental Model/Theory of Mind of AI, What Are They Really Talking About?&#34;&lt;/a&gt;. Xiaoyun Yin, Elmira Zahmat Doost, Shiwen Zhou, Garima Arya Yadav, Jamie Gorman. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=b4rjIlubQk&#34;&gt;&#34;The Mechanistic Emergence of Symbol Grounding in Language Models&#34;&lt;/a&gt;. Ziqiao Ma, Shuyu Wu, Xiaoxi Luo, Yidong Huang, Josue Torres-Fonseca, Freda Shi, Joyce Chai. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=85qCIuZUYw&#34;&gt;&#34;Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models&#34;&lt;/a&gt;. Ruixuan Deng, Xiaoyang Hu, Miles Gilberti, Shane Storks, Aman Taxali, Mike Angstadt, Chandra Sripada, Joyce Chai. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=Z7Bw5CciUx&#34;&gt;&#34;Tracing the Development of Syntax and Semantics in a Model trained on Child-Directed Speech and Visual Input&#34;&lt;/a&gt;. Nina Schoener, Mahesh Srinivasan, Colin Conwell. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=zcViXXDU53&#34;&gt;&#34;Conflict Adaptation in Vision-Language Models&#34;&lt;/a&gt;. Xiaoyang Hu. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=KUUHAQxwzh&#34;&gt;&#34;Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques&#34;&lt;/a&gt;. Lang Xiong, Raina Gao, Alyssa Jeong, Yicheng Fu, Kevin Zhu, Sean O&#39;Brien, Vasu Sharma. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=WgJlyHmY2x&#34;&gt;&#34;Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld&#39;s Episode Theory&#34;&lt;/a&gt;. Ming Li, Nan Zhang, Chenrui Fan, Hong Jiao, Tianyi Zhou. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=VBoove4NEj&#34;&gt;&#34;Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment Analysis&#34;&lt;/a&gt;. Amartya Hatua. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=s4rYWilqgr&#34;&gt;&#34;Strategy and structure in Codenames: Comparing human and GPT-4 gameplay&#34;&lt;/a&gt;. Noah Prescott, Tracey Mills, Jonathan Phillips. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=IgsyaVN3Cf&#34;&gt;&#34;Language models can associate objects with their features without forming integrated representations&#34;&lt;/a&gt;. Simon Jerome Han, James Lloyd McClelland. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=WksqQxYZXs&#34;&gt;&#34;Unifying Gestalt Principles Through Inference-Time Prior Integration&#34;&lt;/a&gt;. Tahereh Toosi, Kenneth D. Miller. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=sCQRh2iSxu&#34;&gt;&#34;Assessing Behavioral Effects of Reasoning (or the lack of) in LLMs&#34;&lt;/a&gt;. ARTHUR BUZELIN, Samira Malaquias, Victoria Estanislau, Yan Aquino, Pedro Augusto Torres Bento, Lucas Dayrell, Arthur Chagas, Gisele L. Pappa, Wagner Meira Jr.. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=ba2B4vty8t&#34;&gt;&#34;Actual or counterfactual? Asymmetric responsibility attributions in language models&#34;&lt;/a&gt;. Eric Bigelow, Yang Xiang, Tobias Gerstenberg, Tomer Ullman, Samuel J. Gershman. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=4gs6ZAzSkZ&#34;&gt;&#34;Theoretical Linguistics Constrains Hypothesis-Driven Causal Abstraction in Mechanistic Interpretability&#34;&lt;/a&gt;. Suchir Salhan, Konstantinos Voudouris. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=djvUhtakoH&#34;&gt;&#34;Language Models use Lookbacks to Track Beliefs&#34;&lt;/a&gt;. Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma, Christoph Riedl, Yonatan Belinkov, Tamar Rott Shaham, David Bau, Atticus Geiger. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=5xgaeuSpAm&#34;&gt;&#34;Scratchpad Thinking: Alternation Between Storage and Computation in Latent Reasoning Models&#34;&lt;/a&gt;. Sayam Goyal, Brad Peters, María Emilia Granda, Akshath Vijayakumar Narmadha, Dharunish Yugeswardeenoo, Callum Stuart McDougall, Sean O&#39;Brien, Ashwinee Panda, Kevin Zhu, Cole Blondin. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=HUJRXlz5Rh&#34;&gt;&#34;STAT: Skill-Targeted Adaptive Training&#34;&lt;/a&gt;. Yinghui He, Abhishek Panigrahi, Yong Lin, Sanjeev Arora. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=WjDtKptjzH&#34;&gt;&#34;Priors in Time: A Generative View of Sparse Autoencoders for Sequential Representations&#34;&lt;/a&gt;. Ekdeep Singh Lubana, Sai Sumedh R. Hindupur, Can Rager, Valérie Costa, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Greta Tuckute, Daniel Wurgaft, Demba E. Ba, Melanie Weber, Aaron Mueller. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=OQoPp5r6ci&#34;&gt;&#34;Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows&#34;&lt;/a&gt;. Billy Dickson, Zoran Tiganj. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=MUUSfjQtgA&#34;&gt;&#34;Are Humans Evolved Instruction Followers? An Underlying Inductive Bias Enables Rapid Instructed Task Learning&#34;&lt;/a&gt;. Anjishnu Kumar. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=eHEoujt4BF&#34;&gt;&#34;Visual symbolic mechanisms: Emergent symbol processing in vision language models&#34;&lt;/a&gt;. Rim Assouel, Declan Iain Campbell, Taylor Whittington Webb. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=YzUYaY9A6F&#34;&gt;&#34;Let&#39;s Think 一步一步: A Cognitive Framework for Characterizing Code-Switching in LLM Reasoning&#34;&lt;/a&gt;. Eleanor Lin, David Jurgens. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=UkixGllDyG&#34;&gt;&#34;Disaggregation Reveals Hidden Training Dynamics: The Case of Agreement Attraction&#34;&lt;/a&gt;. James A. Michaelov, Catherine Arnett. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=XBijuwB9j4&#34;&gt;&#34;Video Finetuning Improves Reasoning Between Frames&#34;&lt;/a&gt;. Ruiqi Yang, Tian Yun, Zihan Wang, Ellie Pavlick. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=lz14CoUBkq&#34;&gt;&#34;Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning&#34;&lt;/a&gt;. Caroline Baumgartner, Eleanor Spens, Neil Burgess, Petru Manescu. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=tZl1UHn8Ru&#34;&gt;&#34;A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy&#34;&lt;/a&gt;. Claire O&#39;Brien, Jessica Seto, Dristi Roy, Aditya Dwivedi, Ryan Lagasse, Sunishchal Dev, Kevin Zhu, Sean O&#39;Brien. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=EY5nlcduay&#34;&gt;&#34;Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm&#34;&lt;/a&gt;. Amrapali Pednekar, Álvaro Garrido Pérez, Yara Khaluf, Pieter Simoens. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=NCGO8pjWda&#34;&gt;&#34;Neural Correlates of Language Models Are Specific to Human Language&#34;&lt;/a&gt;. Iñigo Parra. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=1XL8DtZiFe&#34;&gt;&#34;Pedagogical Alignment of LLMs requires Diverse Cognitively-Inspired Student Proxies&#34;&lt;/a&gt;. Suchir Salhan, Andrew Caines, Paula Buttery. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=oZT5ikNFdC&#34;&gt;&#34;I Am Large, I Contain Multitudes: Persona Transmission via Contextual Inference in LLMs&#34;&lt;/a&gt;. Puria Radmard, Shi Feng. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=ErlLfsFdX1&#34;&gt;&#34;Personality Manipulation as a Cognitive Probe in Large Language Models&#34;&lt;/a&gt;. Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Colin Treleaven. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=Aj7rRb4A45&#34;&gt;&#34;Kindness or Sycophancy? Understanding and Shaping Model Personality via Synthetic Games&#34;&lt;/a&gt;. Maya Okawa, Ekdeep Singh Lubana, Mai Uchida, Hidenori Tanaka. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=wROFSZZXu9&#34;&gt;&#34;Metacognitive Sensitivity for Test-Time Dynamic Model Selection&#34;&lt;/a&gt;. Le Tuan Minh Trinh, Le Minh Vu Pham, Thi Minh Anh Pham, An Duc Nguyen. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=sDSlefEnCF&#34;&gt;&#34;Causality $\neq$ Decodability, and Vice Versa: Lessons from Interpreting Counting ViTs&#34;&lt;/a&gt;. Lianghuan Huang, Yingshan Chang. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=5wGbjZsdBi&#34;&gt;&#34;Context informs pragmatic interpretation in vision–language models&#34;&lt;/a&gt;. Alvin Wei Ming Tan, Ben Prystawski, Veronica Boyce, Michael Frank. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=c3GL3vDggf&#34;&gt;&#34;Unraveling the cognitive patterns of Large Language Models through module communities&#34;&lt;/a&gt;. Kushal Raj Bhandari, Pin-Yu Chen, Jianxi Gao. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=NdL3PSmIyj&#34;&gt;&#34;DecepBench: Benchmarking Multimodal Deception Detection&#34;&lt;/a&gt;. Vittesh Maganti, Nysa Lalye, Ethan Braverman, Kevin Zhu, Vasu Sharma, Sean O&#39;Brien. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=WfqVHXLHBq&#34;&gt;&#34;Misalignment Between Vision-Language Representations in Vision-Language Models&#34;&lt;/a&gt;. Yonatan Gideoni, Yoav Gelberg, Tim G. J. Rudner, Yarin Gal. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=1fN0gDRBkF&#34;&gt;&#34;Detecting Motivated Reasoning in the Internal Representations of Language Models&#34;&lt;/a&gt;. Parsa Mirtaheri, Mikhail Belkin. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=QUYu0FMFXr&#34;&gt;&#34;PluriHarms: Benchmarking the Full Spectrum of Human Judgments on AI Harm&#34;&lt;/a&gt;. Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Maarten Sap, Sydney Levine. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=7oTmEln6vo&#34;&gt;&#34;LLM Agents Beyond Utility: An Open-Ended Perspective&#34;&lt;/a&gt;. Asen Nachkov, Xi Wang, Luc Van Gool. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=IaQU3GH50K&#34;&gt;&#34;Perceived vs. True Emergence: A Cognitive Account of Generalization in Clinical Time Series Models&#34;&lt;/a&gt;. Shashank Yadav. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=PH26cSNsH4&#34;&gt;&#34;A Neuroscience-Inspired Dual-Process Model of Compositional Generalization&#34;&lt;/a&gt;. Alexander Noviello, Claas Beger, Jacob Groner, Kevin Ellis, Weinan Sun. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=5NxVmdeMMz&#34;&gt;&#34;From Black Box to Bedside: Distilling Reinforcement Learning for Interpretable Sepsis Treatment&#34;&lt;/a&gt;. Ella Lan, Andrea Yu, Sergio Charles. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=Q3iTP8Bl6X&#34;&gt;&#34;Measuring LLM Generation Spaces with EigenScore&#34;&lt;/a&gt;. Sunny Yu, Myra Cheng, Ahmad Jabbar, Robert D. Hawkins, Dan Jurafsky. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=WYUfI616Hp&#34;&gt;&#34;Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding&#34;&lt;/a&gt;. Vanessa Figueiredo. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=RJ7w9bEGTI&#34;&gt;&#34;Causal Interventions on Continuous Features in LLMs: A Case Study in Verb Bias&#34;&lt;/a&gt;. Zhenghao Zhou, R. Thomas McCoy, Robert Frank. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=0IcsigkJAS&#34;&gt;&#34;Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behaviour&#34;&lt;/a&gt;. Eric Zhang, Daniel Aarao Reis Arturi, Andrew Adrian Ansah, Kevin Zhu, Ashwinee Panda, Aishwarya Balwani. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=KKjt8VADoT&#34;&gt;&#34;Reverse-Engineering Memory in DreamerV3: From Sparse Representations to Functional Circuits&#34;&lt;/a&gt;. Jan Sobotka, Auke Ijspeert, Guillaume Bellegarda. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=MT9zaJoHjp&#34;&gt;&#34;Does FLUX Know What It’s Writing?&#34;&lt;/a&gt;. Adrian Chang, Sheridan Feucht, Byron C Wallace, David Bau. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=FIgoOA89K0&#34;&gt;&#34;Discovering Functionally Sufficient Projections with Functional Component Analysis&#34;&lt;/a&gt;. Satchel Grant. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=aq2MtJ320b&#34;&gt;&#34;Towards Visual Simulation in Multimodal Language Models&#34;&lt;/a&gt;. Catherine Finegan-Dollak. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=qgDo0ViaDT&#34;&gt;&#34;RNNs reveal a new optimal stopping rule in sequential sampling for decision-making&#34;&lt;/a&gt;. Jialin Li, Kenway Louie, Paul W. Glimcher, Bo Shen. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=srJFgAQ8fC&#34;&gt;&#34;Minimization of Boolean Complexity in In-Context Concept Learning&#34;&lt;/a&gt;. Leroy Z. Wang, R. Thomas McCoy, Shane Steinert-Threlkeld. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=ZSRaoVwb0R&#34;&gt;&#34;Demystifying Emergent Exploration in Goal-conditioned RL&#34;&lt;/a&gt;. Mahsa Bastankhah, Grace Liu, Dilip Arumugam, Thomas L. Griffiths, Benjamin Eysenbach. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=toaajUTyID&#34;&gt;&#34;Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment&#34;&lt;/a&gt;. María Victoria Carro, Denise Alejandra Mester, Francisca Gauna Selasco, Giovanni Franco Gabriel Marraffini, Mario Leiva, Gerardo Simari, Maria Vanina Martinez. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=6Bbuqennw0&#34;&gt;&#34;How Do LLMs Ask Questions? A Pragmatic Comparison with Human Question-Asking&#34;&lt;/a&gt;. Chani Jung, Jimin Mun, Xuhui Zhou, Alice Oh, Maarten Sap, Hyunwoo Kim. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=tkgxDkAVBv&#34;&gt;&#34;Predicting the Formation of Induction Heads&#34;&lt;/a&gt;. Tatsuya Aoyama, Ethan Wilcox, Nathan Schneider. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=F92Z5hsS11&#34;&gt;&#34;How Intrinsic Motivation Shapes Learned Representations in Decision Transformers: A Cognitive Interpretability Analysis&#34;&lt;/a&gt;. Leonardo Guiducci, Antonio Rizzo, Giovanna Maria Dimitri. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=7asnUDuVPR&#34;&gt;&#34;Decoding and Reconstructing Visual Experience from Brain Activity with Generative Latent Representations&#34;&lt;/a&gt;. Motokazu Umehara, Yoshihiro Nagano, Misato Tanaka, Yukiyasu Kamitani. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=eF2lcYSF0V&#34;&gt;&#34;From Comparison to Composition: Towards Understanding Machine Cognition of Unseen Categories&#34;&lt;/a&gt;. Minghao Fu, Sheng Zhang, Guangyi Chen, Zijian Li, Fan Feng, Yifan Shen, Shaoan Xie, Kun Zhang. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=HyfwJjytjB&#34;&gt;&#34;Disentangling Interpretable Cognitive Variables That Support Human Generalization&#34;&lt;/a&gt;. Xinyue Zhu, Daniel L. Kimmel. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=pjBVkyzwu8&#34;&gt;&#34;Interpreting style–content parsing in vision–language models&#34;&lt;/a&gt;. Fan L. Cheng, Xin Jing. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=S7r9LaYvdT&#34;&gt;&#34;Acoustic Degradation Reweights Cortical and ASR  Processing: A Brain-Model Alignment Study&#34;&lt;/a&gt;. Francis Pingfan Chien, Chia-Chun Dan Hsu, Po-Jang Hsieh, Yu Tsao. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=PNtwdoaihO&#34;&gt;&#34;Towards Cognitively Plausible Concept Learning: Spatially Grounding Concepts with Anatomical Priors&#34;&lt;/a&gt;. Yuyu Zhou. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=fd2Ssf8mMJ&#34;&gt;&#34;(How) Do LLMs Plan in One Forward Pass?&#34;&lt;/a&gt;. Michael Hanna, Emmanuel Ameisen. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=M9RFmHxrKM&#34;&gt;&#34;Value Entanglement: Conflation Between Moral and Grammatical Good In (Some) Large Language Models&#34;&lt;/a&gt;. Seong Hah Cho, Junyi Li, Anna Leshinskaya. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=6zzLOfIEnF&#34;&gt;&#34;Stop Anthropomorphizing Intermediate Tokens as Reasoning/Thinking Traces!&#34;&lt;/a&gt;. Subbarao Kambhampati, Kaya Stechly, Karthik Valmeekam, Lucas Paul Saldyt, Siddhant Bhambri, Vardhan Palod, Atharva Gundawar, Soumya Rani Samineni, Durgesh Kalwar, Upasana Biswas. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=apA1XvmQV3&#34;&gt;&#34;Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?&#34;&lt;/a&gt;. Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=Ca6YfIpVBB&#34;&gt;&#34;What is a Number, That a Large Language Model May Know It?&#34;&lt;/a&gt;. Raja Marjieh, Veniamin Veselovsky, Thomas L. Griffiths, Ilia Sucholutsky. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=oB5MqHvEvL&#34;&gt;&#34;NiceWebRL: a Python library for human subject experiments with reinforcement learning environments&#34;&lt;/a&gt;. Wilka Carvalho, Vikram Srinivas Goddla, Ishaan Sinha, Hoon Shin, Kunal Jha. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=5kyIDVYrUv&#34;&gt;&#34;The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends&#34;&lt;/a&gt;. Nico Policzer, Cameron Braunstein, Mariya Toneva. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=iErDWmZD7y&#34;&gt;&#34;Signatures of human-like processing in Transformer forward passes&#34;&lt;/a&gt;. Jennifer Hu, Michael A. Lepori, Michael Franke. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=tRCsbjBIZ5&#34;&gt;&#34;CurLL: Curriculum Learning of Language Models&#34;&lt;/a&gt;. Pavan Kalyan Tankala, Shubhra Mishra, Satya Lokam, Navin Goyal. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=ZhJ6WPw0mp&#34;&gt;&#34;Learning to Look: Cognitive Attention Alignment with Vision-Language Models&#34;&lt;/a&gt;. Ryan L. Yang, Dipkamal Bhusal, Nidhi Rastogi. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=Ytm6dF43lP&#34;&gt;&#34;Deconstructing the Reasoning Process of a Neuro-Fuzzy Agent: From Learned Concepts to Natural Language Narratives&#34;&lt;/a&gt;. Yumin Zhou, Whye Loon Tung, Hiok Quek. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=4OdHkADJw9&#34;&gt;&#34;A Cognitive Architecture for Probing Hierarchical Processing and Predictive Coding in Deep Vision Models&#34;&lt;/a&gt;. Brennen Hill, Zhang Xinyu, Timothy Putra Prasetio. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=SDdpJUm4v7&#34;&gt;&#34;Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence&#34;&lt;/a&gt;. Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=38yw6kthZW&#34;&gt;&#34;Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation&#34;&lt;/a&gt;. Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;a href=&#34;https://openreview.net/forum?id=0FhGN9j5xJ&#34;&gt;&#34;MetaCD: A Meta Learning Framework for Cognitive Diagnosis based on Continual Learning&#34;&lt;/a&gt;. Jin Wu, Chanjin Zheng. &#xA;&lt;br&gt;&lt;br&gt;&#xA;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Call for Papers</title>
      <link>http://localhost:1313/neurips2025/call-for-papers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/call-for-papers/</guid>
      <description>&lt;h1 id=&#34;call-for-papers&#34;&gt;Call for Papers&lt;/h1&gt;&#xA;&lt;p&gt;We will invite submissions (4-page papers, both technical and positional in nature) covering or bridging the following themes. We note that these themes are not mutually exclusive, and papers may touch on multiple&#xA;themes.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Behavioral accounts&lt;/strong&gt;. What kinds of generalizations have models learned about cognitively important&#xA;tasks? What kinds of cues, biases, or heuristics might affect a model’s performance on these tasks? What&#xA;kind of cognitive frameworks best characterize model behaviors?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; Hypothesis-driven evaluations of high-level cognitive behaviors [1–8]; understanding how heuristics and task demands affect model behaviors [9–15]; and fitting cognitive models to deep neural network behavioral data [16–19]&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; Evaluations of deep learning models which do not make claims about the underlying processes driving their behavior, or behavioral experiments with AI models which seek to further our understanding of the human mind, rather than our understanding of AI models&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Processing accounts&lt;/strong&gt;. What algorithms underlie the behaviors models exhibit when performing key&#xA;high-level cognitive tasks? How are these algorithms implemented? How do these algorithms relate to&#xA;behaviors expected of a rational agent performing such tasks?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; Using interpretability tools to understand cognitive processing algorithms [e.g., 20–27]; explaining how heuristic strategies interact with rule-based generalization behaviors [28–31]; and behavioral investigations of algorithms underlying complex tasks [32–36].&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; Design, validation, or demonstration of interpretability tools that are directed towards identifying or explaining narrow skills that are not instrumental towards performing complex tasks (e.g., work identifying neurons activating for prominent monuments), or not motivated towards explaining model cognition (e.g., work on identifying mechanisms to refuse unsafe queries by a model).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;&lt;strong&gt;Developmental accounts&lt;/strong&gt;. How do certain cognitive abilities emerge or develop across learning? What properties of the training data distribution or objective functions contribute to downstream behaviors? How does the model’s training environment relate to predispositions supported by the model’s architecture or other forms of inductive bias? Relevant perspectives from cognitive science that could help shed light on these questions include developmental psychology, learning theory, and evolutionary biology.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics within scope:&lt;/ins&gt; Evaluations of learning inspired by cognitive theories  [37–40]; identifying models’ inductive biases [e.g., 41–44]; and understanding downstream effects of data distribution on behavior and generalization  [e.g., 45–50].&lt;/li&gt;&#xA;&lt;li&gt;&lt;ins&gt;Example topics potentially out of scope:&lt;/ins&gt; Developmental accounts that do not attempt to contextualize cognitive theories or tools for understanding how neural networks learn their capabilities: e.g., work on scaling laws or learning dynamics in the lazy regime.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;submission&#34;&gt;Submission&lt;/h2&gt;&#xA;&lt;p&gt;The submission will be open on &lt;a href=&#34;https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/CogInterp&#34;&gt;OpenReview&lt;/a&gt; between July 9 and August &lt;s&gt;&lt;span style=&#34;color: silver&#34;&gt;22&lt;/span&gt;&lt;/s&gt; 27, 2025 (midnight AoE). For all relevant dates, please see &lt;a href=&#34;http://localhost:1313/neurips2025/#dates&#34;&gt;Important Dates&lt;/a&gt;. The formatting instructions are provided below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Formatting Instructions</title>
      <link>http://localhost:1313/neurips2025/formatting-instructions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/formatting-instructions/</guid>
      <description>&lt;h1 id=&#34;formatting-instructions&#34;&gt;Formatting Instructions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;style--author-instructions&#34;&gt;Style &amp;amp; Author Instructions&lt;/h2&gt;&#xA;&lt;p&gt;Submissions should be formatted using the &lt;a href=&#34;https://media.neurips.cc/Conferences/NeurIPS2025/Styles.zip&#34;&gt;NeurIPS 2025 latex template and formatting instructions&lt;/a&gt;. Papers must be submitted as a PDF file and there will be a strict upper limit of 4 pages for the main text, which should include all main results, figures, and tables. This page limit applies to both the initial and final camera ready version., including all main results, figures, and tables. There is no page limit for the citations, and additional appendices for supplementary details are allowed, but reviewers are not expected to take the appendices into account.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Invited Speakers</title>
      <link>http://localhost:1313/neurips2025/speakers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/speakers/</guid>
      <description>&lt;h1 id=&#34;invited-speakers&#34;&gt;Invited Speakers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/jay.jpeg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://web.stanford.edu/~jlmcc/&#34; target=&#34;_blank&#34;&gt;James McClelland&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/chris.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://stanford.edu/~cgpotts/&#34; target=&#34;_blank&#34;&gt;Christopher Potts&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/stephanie.jpeg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=bXOt49QAAAAJ&#34; target=&#34;_blank&#34;&gt;Stephanie Chan&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/mariya.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://mtoneva.com/&#34; target=&#34;_blank&#34;&gt;Mariya Toneva&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/ari.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://ariholtzman.com/&#34; target=&#34;_blank&#34;&gt;Ari Holtzman&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;td&gt;&lt;img src=&#34;http://localhost:1313/neurips2025/speakers/sydney.jpg&#34;&gt;&lt;/td&gt;&#xA;        &lt;td&gt;&lt;a href=&#34;https://sites.google.com/site/sydneymlevine/&#34; target=&#34;_blank&#34;&gt;Sydney Levine&lt;/a&gt;&lt;/td&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;!-- &lt; Speaker bios to be added soon &gt; --&gt;&#xA;&lt;!-- &#xA;&lt;div id=&#34;bio-zeynep&#34;&gt;&#xA;&#xA;  ## Zeynep Akata&#xA;&#xA;  Zeynep Akata is a professor of Computer Science (W3) within the Cluster of&#xA;  Excellence Machine Learning at the University of Tübingen.  After completing&#xA;  her PhD at the INRIA Rhone Alpes with Prof Cordelia Schmid (2014), she&#xA;  worked as a post-doctoral researcher at the Max Planck Institute for&#xA;  Informatics with Prof Bernt Schiele (2014-17) and at University of&#xA;  California Berkeley with Prof Trevor Darrell (2016-17). Before moving to&#xA;  Tübingen in October 2019, she was an assistant professor at the University&#xA;  of Amsterdam with Prof Max Welling (2017-19). She received a Lise-Meitner&#xA;  Award for Excellent Women in Computer Science from Max Planck Society in&#xA;  2014, a young scientist honour from the Werner-von-Siemens-Ring foundation&#xA;  in 2019 and an ERC-2019 Starting Grant from the European Commission. Her&#xA;  research interests include multimodal learning and explainable AI.&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;div id=&#34;bio-kristen&#34;&gt;&#xA;&#xA;  ## Kristen Grauman&#xA;&#xA;  Kristen Grauman is a Professor in the Department of Computer Science at the&#xA;  University of Texas at Austin and a Research Director in Facebook AI&#xA;  Research (FAIR).  Her research in computer vision and machine learning&#xA;  focuses on video, visual recognition, and action for perception or embodied&#xA;  AI.  Before joining UT-Austin in 2007, she received her Ph.D. at MIT.  She&#xA;  is an IEEE Fellow, AAAI Fellow, Sloan Fellow, a Microsoft Research New&#xA;  Faculty Fellow, and a recipient of NSF CAREER and ONR Young Investigator&#xA;  awards, the PAMI Young Researcher Award in 2013, the 2013 Computers and&#xA;  Thought Award from the International Joint Conference on Artificial&#xA;  Intelligence (IJCAI), the Presidential Early Career Award for Scientists and&#xA;  Engineers (PECASE) in 2013.  She was inducted into the UT Academy of&#xA;  Distinguished Teachers in 2017.  She and her collaborators have been&#xA;  recognized with several Best Paper awards in computer vision, including a&#xA;  2011 Marr Prize and a 2017 Helmholtz Prize (test of time award).  She served&#xA;  for six years as an Associate Editor-in-Chief for the Transactions on&#xA;  Pattern Analysis and Machine Intelligence (PAMI) and for ten years as an&#xA;  Editorial Board member for the International Journal of Computer Vision&#xA;  (IJCV).  She also served as a Program Chair of the IEEE Conference on&#xA;  Computer Vision and Pattern Recognition (CVPR) 2015 and a Program Chair of&#xA;  Neural Information Processing Systems (NeurIPS) 2018, and will serve as a&#xA;  Program Chair of the IEEE International Conference on Computer Vision (ICCV)&#xA;  2023.&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;div id=&#34;bio-paul&#34;&gt;&#xA;&#xA;  ## Paul Liang&#xA;&#xA;  Paul Liang is a Ph.D. student in Machine Learning at CMU, advised by&#xA;  Louis-Philippe Morency and Ruslan Salakhutdinov. His research lies in the&#xA;  foundations of multimodal machine learning with applications in socially&#xA;  intelligent AI, understanding human and machine intelligence, natural&#xA;  language processing, healthcare, and education. He is a recipient of the&#xA;  Facebook PhD Fellowship, Center for Machine Learning and Health Fellowship,&#xA;  and the Alan J. Perlis Graduate Student Teaching Award, and his research has&#xA;  been recognized by 3 best-paper awards at NeurIPS workshops and ICMI. He&#xA;  regularly organizes courses, workshops, and tutorials on multimodal machine&#xA;  learning.&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;div id=&#34;bio-arsha&#34;&gt;&#xA;&#xA;  ## Arsha Nagrani&#xA;&#xA;  Arsha Nagrani is a senior research scientist at Google AI Research, where&#xA;  she works on machine learning for video understanding. She got her PhD in&#xA;  the VGG group with Andrew Zisserman at the University of Oxford, supported&#xA;  by an EPSRC grant and a Google PhD Fellowship Award. Her thesis “Video&#xA;  Understanding using Multimodal Deep Learning” won the 2021 ELLIS PhD award.&#xA;  Her research focuses on self-supervised and multi-modal machine learning&#xA;  techniques for video recognition, including the use of sound and text to&#xA;  learn better visual representations.&#xA;&#xA;&lt;/div&gt;&#xA;&#xA;&#xA;&lt;div id=&#34;bio-sid&#34;&gt;&#xA;&#xA;  ## Siddharth Narayanaswamy&#xA;&#xA;  Siddharth N. is a Reader in Explainable AI in the School of&#xA;  Informatics at the University of Edinburgh, a part-time Senior Research&#xA;  Fellow at the Alan Turing Institute, a Visiting Fellow at the Department of&#xA;  Engineering Science at the University of Oxford, and an ELLIS Scholar. He&#xA;  was previously a Senior Researcher in Engineering at the University of&#xA;  Oxford and a Postdoctoral Scholar in Psychology at Stanford. He obtained his&#xA;  PhD from Purdue University in Electrical and Computer Engineering.&#xA;  His research interests are broadly cross-disciplinary and motivated by&#xA;  problems found at the intersection of machine learning, computer vision,&#xA;  natural-language processing, cognitive science, robotics, and neuroscience.&#xA;  In particular, he is interested in unsupervised learning of structured&#xA;  representations from perceptual data, and establishing common ground between&#xA;  machines and humans through interaction, with implications for building&#xA;  robust, generalisable, and interpretable AI and ML systems.&#xA;&#xA;&lt;/div&gt;&#xA; --&gt;</description>
    </item>
    <item>
      <title>Organizers</title>
      <link>http://localhost:1313/neurips2025/organizers-reviewers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/organizers-reviewers/</guid>
      <description>&lt;h1 id=&#34;organizers&#34;&gt;Organizers&lt;/h1&gt;&#xA;&lt;div class=&#34;list-of-people&#34;&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/jenn.png&#34;&gt;&#xA;        &lt;a href=&#34;https://jennhu.github.io&#34; target=&#34;_blank&#34;&gt;Jennifer Hu&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/ekdeep.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://ekdeepslubana.github.io&#34; target=&#34;_blank&#34;&gt;Ekdeep Singh Lubana&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/eric.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://scholar.google.com/citations?user=wpppofoAAAAJ&#34; target=&#34;_blank&#34;&gt;Eric Bigelow&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!-- TODO: images for each of these --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/kanishk.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://www.kanishkgandhi.com&#34; target=&#34;_blank&#34;&gt;Kanishk Gandhi&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/laura.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://lauraruis.github.io&#34; target=&#34;_blank&#34;&gt;Laura Ruis&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/thomas.png&#34;&gt;&#xA;        &lt;a href=&#34;https://thomasfel.me&#34; target=&#34;_blank&#34;&gt;Thomas Fel&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/ellie.jpg&#34;&gt;&#xA;        &lt;a href=&#34;https://cs.brown.edu/people/epavlick/&#34; target=&#34;_blank&#34;&gt;Ellie Pavlick&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;person&#34;&gt;&#xA;        &lt;img src=&#34;http://localhost:1313/neurips2025/organizing-team/noah.jpeg&#34;&gt;&#xA;        &lt;a href=&#34;https://cocolab.stanford.edu/ndg&#34; target=&#34;_blank&#34;&gt;Noah Goodman&lt;/a&gt;&#xA;    &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;contact&#34;&gt;Contact&lt;/h2&gt;&#xA;&lt;p&gt;For any questions or comments, please contact us at &lt;a href=&#34;mailto:coginterp@gmail.com&#34;&gt;coginterp@gmail.com&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;!-- ---&#xA;&#xA;# Acknowledgements&#xA;&#xA;We acknowledge and greatly appreciate the help of all reviewers and members of the program committee who made this workshop possible. --&gt;&#xA;&lt;!-- &lt;table class=&#34;table table-bordered table-hover table-condensed&#34;&gt;&#xA;&lt;tbody&gt;&lt;tr&gt;&#xA;&lt;td&gt;Abhishek Sinha&lt;/td&gt;&#xA;&lt;td&gt; Waymo&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;AJ Piergiovanni&lt;/td&gt;&#xA;&lt;td&gt; Google&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Alain Ryser&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Aleksandr Panov&lt;/td&gt;&#xA;&lt;td&gt; Artificial Intelligence Research Institute&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Alexander Marx&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Alexey Kovalev&lt;/td&gt;&#xA;&lt;td&gt; Artificial Intelligence Research Institute&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Alice Bizeul&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Amro Kamal Mohamed Abbas &amp;nbsp&lt;/td&gt;&#xA;&lt;td&gt; The African Institute For Mathematical Sciences&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Anthony Zhe Liu&lt;/td&gt;&#xA;&lt;td&gt; University of Michigan&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Batuhan Koyuncu&lt;/td&gt;&#xA;&lt;td&gt; Saarland University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Chaerin Kong&lt;/td&gt;&#xA;&lt;td&gt; Seoul National University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Christopher Wang&lt;/td&gt;&#xA;&lt;td&gt; MIT CSAIL&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Colin Conwell&lt;/td&gt;&#xA;&lt;td&gt; Harvard University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Dan Ruta&lt;/td&gt;&#xA;&lt;td&gt; University of Surrey&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Daniel Barrejon&lt;/td&gt;&#xA;&lt;td&gt; Universidad Carlos III de Madrid&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Daphné Chopard&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Dmitry Yudin&lt;/td&gt;&#xA;&lt;td&gt; Artificial Intelligence Research Intsitute&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Dota Tianai Dong&lt;/td&gt;&#xA;&lt;td&gt; Max Planck Institute for Psycholinguistics &lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Emanuele Palumbo&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Fábio Vital&lt;/td&gt;&#xA;&lt;td&gt; Instituto Superior Técnico, Lisboa&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Farah Shamout&lt;/td&gt;&#xA;&lt;td&gt; New York University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Francisco S. Melo&lt;/td&gt;&#xA;&lt;td&gt; Instituto Superior Técnico, Lisboa&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Gaurav Mishra&lt;/td&gt;&#xA;&lt;td&gt; Indian Institute of Technology, Delhi&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Hang Yin&lt;/td&gt;&#xA;&lt;td&gt; KTH Royal Institute of Technology&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Harsh Shrivastava&lt;/td&gt;&#xA;&lt;td&gt; Microsoft&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Heike Leutheuser&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Henrique Aguiar&lt;/td&gt;&#xA;&lt;td&gt; University of Oxford&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Hiroki Furuta&lt;/td&gt;&#xA;&lt;td&gt; The University of Tokyo&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Ilaria Manco&lt;/td&gt;&#xA;&lt;td&gt; Queen Mary University of London&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Jonas Klesen&lt;/td&gt;&#xA;&lt;td&gt; Saarland University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Krikamol Muandet&lt;/td&gt;&#xA;&lt;td&gt; CISPA - Helmholtz Center for Information Security&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Mariya Toneva&lt;/td&gt;&#xA;&lt;td&gt; Max Planck Institute for Software Systems&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Masahiro Suzuki&lt;/td&gt;&#xA;&lt;td&gt; The University of Tokyo, Tokyo Institute of Technology&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Nona Rajabi&lt;/td&gt;&#xA;&lt;td&gt; KTH Royal Institute of Technology&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Pablo Sanchez Martin&lt;/td&gt;&#xA;&lt;td&gt; Max Planck Institute for Intelligent Systems&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Peiyang Shi&lt;/td&gt;&#xA;&lt;td&gt; KTH Royal Institute of Technology&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Priyank Jaini&lt;/td&gt;&#xA;&lt;td&gt; Google&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Rahim Entezari&lt;/td&gt;&#xA;&lt;td&gt; TU Graz&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Sebastian M. Schmon&lt;/td&gt;&#xA;&lt;td&gt; Durham University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Senthilkumar Gopal&lt;/td&gt;&#xA;&lt;td&gt; eBay Inc&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Simon Kornblith&lt;/td&gt;&#xA;&lt;td&gt; Google&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Sören Richard Stahlschmidt&lt;/td&gt;&#xA;&lt;td&gt; University College of Skövde&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Taihong Xiao&lt;/td&gt;&#xA;&lt;td&gt; University of California at Merced&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Thomas M. Sutter&lt;/td&gt;&#xA;&lt;td&gt; ETH Zurich&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Tom Joy&lt;/td&gt;&#xA;&lt;td&gt; Five AI&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Udita Patel&lt;/td&gt;&#xA;&lt;td&gt; Amazon&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Wenjie Yin&lt;/td&gt;&#xA;&lt;td&gt; KTH Royal Institute of Technology&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Ying Wang&lt;/td&gt;&#xA;&lt;td&gt; New York University&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Yunseok Jang&lt;/td&gt;&#xA;&lt;td&gt; University of Michigan&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;tr&gt;&#xA;&lt;td&gt;Zachary Novack&lt;/td&gt;&#xA;&lt;td&gt; University of California, San Diego&lt;/td&gt;&#xA;&lt;/tr&gt;&#xA;&lt;/tbody&gt;&lt;/table&gt; --&gt;</description>
    </item>
    <item>
      <title>Reviewers</title>
      <link>http://localhost:1313/neurips2025/reviewers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/reviewers/</guid>
      <description>&lt;h1 id=&#34;reviewers&#34;&gt;Reviewers&lt;/h1&gt;&#xA;&lt;p&gt;Adam Li, Columbia University&lt;/p&gt;&#xA;&lt;p&gt;Alexander Hägele, ETHZ - ETH Zurich&lt;/p&gt;&#xA;&lt;p&gt;Biwei Huang, Carnegie Mellon University&lt;/p&gt;&#xA;&lt;p&gt;Bohdan Kivva, University of Chicago&lt;/p&gt;&#xA;&lt;p&gt;Bryon Aragam, University of Chicago&lt;/p&gt;&#xA;&lt;p&gt;Chandler Squires, Massachusetts Institute of Technology&lt;/p&gt;&#xA;&lt;p&gt;Cian Eastwood, University of Edinburgh&lt;/p&gt;&#xA;&lt;p&gt;Daniel Malinsky, Johns Hopkins University&lt;/p&gt;&#xA;&lt;p&gt;Davide Talon, Università degli Studi di Genova, Istituto Italiano di Tecnologia&lt;/p&gt;&#xA;&lt;p&gt;Dhanya Sridhar, Université de Montréal and Mila-Quebec AI Institute&lt;/p&gt;&#xA;&lt;p&gt;Furui Liu, Huawei Technologies Ltd.&lt;/p&gt;&#xA;&lt;p&gt;Gargi Balasubramaniam, University of Illinois, Urbana Champaign&lt;/p&gt;</description>
    </item>
    <item>
      <title>Schedule and Format</title>
      <link>http://localhost:1313/neurips2025/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/neurips2025/schedule/</guid>
      <description>&lt;h1 id=&#34;workshop-schedule&#34;&gt;Workshop Schedule&lt;/h1&gt;&#xA;&lt;p&gt;A tentative schedule of events is given below. The program includes a mix of invited and contributed spotlight talks, as well as interactive activities such as a poster session, built-in breaks for socializing, and a panel discussion.&lt;/p&gt;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-bottom: 18px; margin-top: 18px;&#34;&gt;&#xA;    Legend:&#xA;    &lt;span class=&#34;invited&#34;&gt;invited speakers&lt;/span&gt; · &#xA;    &lt;span class=&#34;contributed&#34;&gt;contributed talk&lt;/span&gt; ·&#xA;    &lt;span class=&#34;poster&#34;&gt;poster session&lt;/span&gt; · &#xA;    &lt;span class=&#34;break&#34;&gt;break&lt;/span&gt;&#xA;&lt;/div&gt;&#xA;&lt;table class=&#34;schedule&#34;&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;th style=&#34;width:40%&#34;&gt;Time&lt;/th&gt;&#xA;        &lt;th&gt;Program&lt;/th&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;08:45 - 09:00&lt;/td&gt;&#xA;        &lt;td&gt;Introduction and Opening Remarks&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;09:00 - 09:30&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 1: Chris Potts&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;09:30 - 10:00&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 2: Stephanie Chan&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;10:00 - 10:10&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 1&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;10:10 - 10:20&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 2&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;10:20 - 10:30&lt;/td&gt;&#xA;        &lt;td&gt;Coffee Break&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;10:30 - 11:00&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 3: Ari Holtzman&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;11:00 - 11:30&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 4: Mariya Toneva&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;11:30 - 11:40&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 3&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;contributed&#34;&gt;&#xA;        &lt;td&gt;11:40 - 11:50&lt;/td&gt;&#xA;        &lt;td&gt;Spotlight Talk 4&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;11:50 - 13:15&lt;/td&gt;&#xA;        &lt;td&gt;Lunch&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;poster&#34;&gt;&#xA;        &lt;td&gt;13:15 - 14:45&lt;/td&gt;&#xA;        &lt;td&gt;Poster Session&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;14:45 - 15:15&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 5: Jay McClelland&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;15:15 - 15:45&lt;/td&gt;&#xA;        &lt;td&gt;Invited Talk 6: Sydney Levine&lt;/td&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr class=&#34;break&#34;&gt;&#xA;        &lt;td&gt;15:45 - 16:00&lt;/td&gt;&#xA;        &lt;td&gt;Coffee Break&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;-&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;!--  --&gt;&#xA;    &lt;tr class=&#34;invited&#34;&gt;&#xA;        &lt;td&gt;16:00 - 17:00&lt;/td&gt;&#xA;        &lt;td&gt;Panel Discussion (with all invited speakers)&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;Live&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;    &lt;tr&gt;&#xA;        &lt;td&gt;17:00 - 17:10&lt;/td&gt;&#xA;        &lt;td&gt;Closing Remarks &amp;amp; Best Paper Award&lt;/td&gt;&#xA;        &lt;!-- &lt;td&gt;Live&lt;/td&gt; --&gt;&#xA;    &lt;/tr&gt;&#xA;&lt;/table&gt;&#xA;&lt;div style=&#34;width: 100%; font-size: smaller; text-align: center; margin-top: 18px;&#34;&gt;&#xA;    &lt;em&gt;All times are for current local time in San Diego, USA.&lt;/em&gt;&#xA;&lt;/div&gt;&#xA;&lt;br&gt;&#xA;&lt;ul&gt;&#xA;    &lt;li&gt; &lt;b&gt;Spotlight Talk 1&lt;/b&gt;: Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression&lt;/li&gt;&#xA;    &lt;li&gt; &lt;b&gt;Spotlight Talk 2&lt;/b&gt;: Interpretable Hybrid Neural-Cognitive Models Discover Cognitive Strategies Underlying Flexible Reversal Learning&lt;/li&gt;&#xA;    &lt;li&gt; &lt;b&gt;Spotlight Talk 3&lt;/b&gt;: Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs&lt;/li&gt;&#xA;    &lt;li&gt; &lt;b&gt;Spotlight Talk 4&lt;/b&gt;: Mechanisms of Symbol Processing in Transformers&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;format&#34;&gt;Format&lt;/h2&gt;&#xA;&lt;p&gt;The workshop is part of NeurIPS and all attendees are requied to register for NeurIPS.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
