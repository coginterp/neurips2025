<!DOCTYPE html>
<html lang="en"><head>

    <meta name="generator" content="Hugo 0.155.3">
    <meta name="date" content="2026-02-08T16:40:42Z">
    
    <meta charset="utf-8">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="no-referrer">
    
    <meta name="author" content="CogInterp Organizers" />
    <meta name="description" content="First Workshop on Interpreting Cognition in Deep Learning Models (NeurIPS 2025)" />
    <meta name="keywords" content="workshop, AI interpretability, cognitive science" />
    
    <title>CogInterp 2025 | Accepted Papers</title>
    
    <meta property="og:title" content="Accepted Papers" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="First Workshop on Interpreting Cognition in Deep Learning Models (NeurIPS 2025)" />
    
    <meta name="twitter:title" content="" />
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;1,300&display=swap" rel="stylesheet"> 
    
    <link rel="canonical" href="https://coginterp.github.io/neurips2025/accepted-papers/">
    <link rel="stylesheet" href="https://coginterp.github.io/neurips2025/styles.css">
    
    <link rel="apple-touch-icon" sizes="180x180" href="https://coginterp.github.io/neurips2025/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://coginterp.github.io/neurips2025/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://coginterp.github.io/neurips2025/favicon-16x16.png">
    <link rel="manifest" href="https://coginterp.github.io/neurips2025/site.webmanifest">

</head>
<body><section id="header">

    <div id="logo-container">
        <div id="title-inner-container">
            <a href="https://coginterp.github.io/neurips2025/"><img src="https://coginterp.github.io/neurips2025/logo.png" width="60%" id="logo"></a>
        </div>
    </div>

    <div id="title-container">
        <div id="title-inner-container">
            <div class="supertitle">First Workshop on</div>
            <div class="title"><a href="https://coginterp.github.io/neurips2025/"><b>CogInterp</b>: Interpreting Cognition <br> in Deep Learning Models</a></div>
            <div class="subtitle">December 7, 2025 @ NeurIPS 2025</div>
        </div>
    </div>

    <br>

    <div id="navigation">
        <ul>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/">About</a></strong></li>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/call-for-papers">Call for Papers</a></strong></li>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/accepted-papers">Accepted Papers</a></strong></li>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/schedule">Schedule</a></strong></li>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/speakers">Speakers</a></strong></li>
        
            <li><strong><a href="https://coginterp.github.io/neurips2025/organizers-reviewers">Organizers</a></strong></li>
        
      </ul>
    </div>

</section><section id="content">
        
    <h1 id="accepted-papers">Accepted Papers</h1>
<div>
<b>Spotlight Talks</b>
<br>
<a href="https://openreview.net/forum?id=8BOs9HYyFe">"Interpretable Hybrid Neural-Cognitive Models Discover Cognitive Strategies Underlying Flexible Reversal Learning"</a>. <a href="https://coginterp.github.io/neurips2025/slides/interp_hybrid_coginterp_present.pptx">(Slides)</a> Chonghao Cai, Liyuan Li, Yifei Cao, Maria K Eckstein.
<br><br>
<a href="https://openreview.net/forum?id=tqp9Cp8quj">"Mechanisms of Symbol Processing in Transformers"</a>. <a href="https://coginterp.github.io/neurips2025/slides/Mechanisms of Symbol Processing in Transformers.pdf">(Slides)</a> Paul Smolensky, Roland Fernandez, Zhenghao Zhou, Mattia Opper, Adam Davies, Jianfeng Gao.
<br><br>
<a href="https://openreview.net/forum?id=kedJDTAoAd">"Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression"</a>. <a href="https://coginterp.github.io/neurips2025/slides/iicll_coginterp_talk_final.pdf">(Slides)</a> Nathaniel Imel, Noga Zaslavsky.
<br><br>
<a href="https://openreview.net/forum?id=foAB8xC74C">"Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs"</a>. <a href="https://coginterp.github.io/neurips2025/slides/many-wolves neurips coginterp.pdf">(Slides)</a> Sonia Krishna Murthy, Rosie Zhao, Jennifer Hu, Sham M. Kakade, Markus Wulfmeier, Peng Qian, Tomer Ullman.
<p><br><br></p>
<p><b>Posters</b>
<br>
<a href="https://openreview.net/forum?id=KTjmPDmHkQ">&ldquo;Cognitive Behavior Modeling via Activation Steering&rdquo;</a>. Anthony Kuang, Ahmed Ismail, Ayo Akinkugbe, Kevin Zhu, Sean O&rsquo;Brien.
<br><br>
<a href="https://openreview.net/forum?id=2ZfC2cErzZ">&ldquo;Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition&rdquo;</a>. Dong Liu, Yanxuan Yu.
<br><br>
<a href="https://openreview.net/forum?id=4RYAkpAbee">&ldquo;Don’t Think of the White Bear: Ironic Negation in Transformer Models under Cognitive Load&rdquo;</a>. Logan Mann, Nayan Saxena, Sarah Tandon, Chenhao Sun, Savar Toteja, Kevin Zhu.
<br><br>
<a href="https://openreview.net/forum?id=cbrdNqtd9y">&ldquo;A Control-Theoretic Account of Cognitive Effort in Language Models&rdquo;</a>. Pranjal Garg.
<br><br>
<a href="https://openreview.net/forum?id=7Abkcg2P6V">&ldquo;On the Role of Pretraining in Domain Adaptation in an Infant-Inspired Distribution Shift Task&rdquo;</a>. Deepayan Sanyal, Joel Phillips Michelson, Maithilee Kunda.
<br><br>
<a href="https://openreview.net/forum?id=pkKO5Kph3o">&ldquo;When Researchers Say Mental Model/Theory of Mind of AI, What Are They Really Talking About?&quot;</a>. Xiaoyun Yin, Elmira Zahmat Doost, Shiwen Zhou, Garima Arya Yadav, Jamie Gorman.
<br><br>
<a href="https://openreview.net/forum?id=b4rjIlubQk">&ldquo;The Mechanistic Emergence of Symbol Grounding in Language Models&rdquo;</a>. Ziqiao Ma, Shuyu Wu, Xiaoxi Luo, Yidong Huang, Josue Torres-Fonseca, Freda Shi, Joyce Chai.
<br><br>
<a href="https://openreview.net/forum?id=85qCIuZUYw">&ldquo;Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models&rdquo;</a>. Ruixuan Deng, Xiaoyang Hu, Miles Gilberti, Shane Storks, Aman Taxali, Mike Angstadt, Chandra Sripada, Joyce Chai.
<br><br>
<a href="https://openreview.net/forum?id=Z7Bw5CciUx">&ldquo;Tracing the Development of Syntax and Semantics in a Model trained on Child-Directed Speech and Visual Input&rdquo;</a>. Nina Schoener, Mahesh Srinivasan, Colin Conwell.
<br><br>
<a href="https://openreview.net/forum?id=zcViXXDU53">&ldquo;Conflict Adaptation in Vision-Language Models&rdquo;</a>. Xiaoyang Hu.
<br><br>
<a href="https://openreview.net/forum?id=KUUHAQxwzh">&ldquo;Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques&rdquo;</a>. Lang Xiong, Raina Gao, Alyssa Jeong, Yicheng Fu, Kevin Zhu, Sean O&rsquo;Brien, Vasu Sharma.
<br><br>
<a href="https://openreview.net/forum?id=WgJlyHmY2x">&ldquo;Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld&rsquo;s Episode Theory&rdquo;</a>. Ming Li, Nan Zhang, Chenrui Fan, Hong Jiao, Tianyi Zhou.
<br><br>
<a href="https://openreview.net/forum?id=VBoove4NEj">&ldquo;Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment Analysis&rdquo;</a>. Amartya Hatua.
<br><br>
<a href="https://openreview.net/forum?id=s4rYWilqgr">&ldquo;Strategy and structure in Codenames: Comparing human and GPT-4 gameplay&rdquo;</a>. Noah Prescott, Tracey Mills, Jonathan Phillips.
<br><br>
<a href="https://openreview.net/forum?id=IgsyaVN3Cf">&ldquo;Language models can associate objects with their features without forming integrated representations&rdquo;</a>. Simon Jerome Han, James Lloyd McClelland.
<br><br>
<a href="https://openreview.net/forum?id=WksqQxYZXs">&ldquo;Unifying Gestalt Principles Through Inference-Time Prior Integration&rdquo;</a>. Tahereh Toosi, Kenneth D. Miller.
<br><br>
<a href="https://openreview.net/forum?id=sCQRh2iSxu">&ldquo;Assessing Behavioral Effects of Reasoning (or the lack of) in LLMs&rdquo;</a>. ARTHUR BUZELIN, Samira Malaquias, Victoria Estanislau, Yan Aquino, Pedro Augusto Torres Bento, Lucas Dayrell, Arthur Chagas, Gisele L. Pappa, Wagner Meira Jr..
<br><br>
<a href="https://openreview.net/forum?id=ba2B4vty8t">&ldquo;Actual or counterfactual? Asymmetric responsibility attributions in language models&rdquo;</a>. Eric Bigelow, Yang Xiang, Tobias Gerstenberg, Tomer Ullman, Samuel J. Gershman.
<br><br>
<a href="https://openreview.net/forum?id=4gs6ZAzSkZ">&ldquo;Theoretical Linguistics Constrains Hypothesis-Driven Causal Abstraction in Mechanistic Interpretability&rdquo;</a>. Suchir Salhan, Konstantinos Voudouris.
<br><br>
<a href="https://openreview.net/forum?id=djvUhtakoH">&ldquo;Language Models use Lookbacks to Track Beliefs&rdquo;</a>. Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma, Christoph Riedl, Yonatan Belinkov, Tamar Rott Shaham, David Bau, Atticus Geiger.
<br><br>
<a href="https://openreview.net/forum?id=5xgaeuSpAm">&ldquo;Scratchpad Thinking: Alternation Between Storage and Computation in Latent Reasoning Models&rdquo;</a>. Sayam Goyal, Brad Peters, María Emilia Granda, Akshath Vijayakumar Narmadha, Dharunish Yugeswardeenoo, Callum Stuart McDougall, Sean O&rsquo;Brien, Ashwinee Panda, Kevin Zhu, Cole Blondin.
<br><br>
<a href="https://openreview.net/forum?id=HUJRXlz5Rh">&ldquo;STAT: Skill-Targeted Adaptive Training&rdquo;</a>. Yinghui He, Abhishek Panigrahi, Yong Lin, Sanjeev Arora.
<br><br>
<a href="https://openreview.net/forum?id=WjDtKptjzH">&ldquo;Priors in Time: A Generative View of Sparse Autoencoders for Sequential Representations&rdquo;</a>. Ekdeep Singh Lubana, Sai Sumedh R. Hindupur, Can Rager, Valérie Costa, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Greta Tuckute, Daniel Wurgaft, Demba E. Ba, Melanie Weber, Aaron Mueller.
<br><br>
<a href="https://openreview.net/forum?id=OQoPp5r6ci">&ldquo;Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows&rdquo;</a>. Billy Dickson, Zoran Tiganj.
<br><br>
<a href="https://openreview.net/forum?id=MUUSfjQtgA">&ldquo;Are Humans Evolved Instruction Followers? An Underlying Inductive Bias Enables Rapid Instructed Task Learning&rdquo;</a>. Anjishnu Kumar.
<br><br>
<a href="https://openreview.net/forum?id=eHEoujt4BF">&ldquo;Visual symbolic mechanisms: Emergent symbol processing in vision language models&rdquo;</a>. Rim Assouel, Declan Iain Campbell, Taylor Whittington Webb.
<br><br>
<a href="https://openreview.net/forum?id=YzUYaY9A6F">&ldquo;Let&rsquo;s Think 一步一步: A Cognitive Framework for Characterizing Code-Switching in LLM Reasoning&rdquo;</a>. Eleanor Lin, David Jurgens.
<br><br>
<a href="https://openreview.net/forum?id=UkixGllDyG">&ldquo;Disaggregation Reveals Hidden Training Dynamics: The Case of Agreement Attraction&rdquo;</a>. James A. Michaelov, Catherine Arnett.
<br><br>
<a href="https://openreview.net/forum?id=XBijuwB9j4">&ldquo;Video Finetuning Improves Reasoning Between Frames&rdquo;</a>. Ruiqi Yang, Tian Yun, Zihan Wang, Ellie Pavlick.
<br><br>
<a href="https://openreview.net/forum?id=lz14CoUBkq">&ldquo;Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning&rdquo;</a>. Caroline Baumgartner, Eleanor Spens, Neil Burgess, Petru Manescu.
<br><br>
<a href="https://openreview.net/forum?id=tZl1UHn8Ru">&ldquo;A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy&rdquo;</a>. Claire O&rsquo;Brien, Jessica Seto, Dristi Roy, Aditya Dwivedi, Ryan Lagasse, Sunishchal Dev, Kevin Zhu, Sean O&rsquo;Brien.
<br><br>
<a href="https://openreview.net/forum?id=EY5nlcduay">&ldquo;Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm&rdquo;</a>. Amrapali Pednekar, Álvaro Garrido Pérez, Yara Khaluf, Pieter Simoens.
<br><br>
<a href="https://openreview.net/forum?id=NCGO8pjWda">&ldquo;Neural Correlates of Language Models Are Specific to Human Language&rdquo;</a>. Iñigo Parra.
<br><br>
<a href="https://openreview.net/forum?id=1XL8DtZiFe">&ldquo;Pedagogical Alignment of LLMs requires Diverse Cognitively-Inspired Student Proxies&rdquo;</a>. Suchir Salhan, Andrew Caines, Paula Buttery.
<br><br>
<a href="https://openreview.net/forum?id=oZT5ikNFdC">&ldquo;I Am Large, I Contain Multitudes: Persona Transmission via Contextual Inference in LLMs&rdquo;</a>. Puria Radmard, Shi Feng.
<br><br>
<a href="https://openreview.net/forum?id=ErlLfsFdX1">&ldquo;Personality Manipulation as a Cognitive Probe in Large Language Models&rdquo;</a>. Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Colin Treleaven.
<br><br>
<a href="https://openreview.net/forum?id=Aj7rRb4A45">&ldquo;Kindness or Sycophancy? Understanding and Shaping Model Personality via Synthetic Games&rdquo;</a>. Maya Okawa, Ekdeep Singh Lubana, Mai Uchida, Hidenori Tanaka.
<br><br>
<a href="https://openreview.net/forum?id=wROFSZZXu9">&ldquo;Metacognitive Sensitivity for Test-Time Dynamic Model Selection&rdquo;</a>. Le Tuan Minh Trinh, Le Minh Vu Pham, Thi Minh Anh Pham, An Duc Nguyen.
<br><br>
<a href="https://openreview.net/forum?id=sDSlefEnCF">&ldquo;Causality $\neq$ Decodability, and Vice Versa: Lessons from Interpreting Counting ViTs&rdquo;</a>. Lianghuan Huang, Yingshan Chang.
<br><br>
<a href="https://openreview.net/forum?id=5wGbjZsdBi">&ldquo;Context informs pragmatic interpretation in vision–language models&rdquo;</a>. Alvin Wei Ming Tan, Ben Prystawski, Veronica Boyce, Michael Frank.
<br><br>
<a href="https://openreview.net/forum?id=c3GL3vDggf">&ldquo;Unraveling the cognitive patterns of Large Language Models through module communities&rdquo;</a>. Kushal Raj Bhandari, Pin-Yu Chen, Jianxi Gao.
<br><br>
<a href="https://openreview.net/forum?id=NdL3PSmIyj">&ldquo;DecepBench: Benchmarking Multimodal Deception Detection&rdquo;</a>. Vittesh Maganti, Nysa Lalye, Ethan Braverman, Kevin Zhu, Vasu Sharma, Sean O&rsquo;Brien.
<br><br>
<a href="https://openreview.net/forum?id=WfqVHXLHBq">&ldquo;Misalignment Between Vision-Language Representations in Vision-Language Models&rdquo;</a>. Yonatan Gideoni, Yoav Gelberg, Tim G. J. Rudner, Yarin Gal.
<br><br>
<a href="https://openreview.net/forum?id=1fN0gDRBkF">&ldquo;Detecting Motivated Reasoning in the Internal Representations of Language Models&rdquo;</a>. Parsa Mirtaheri, Mikhail Belkin.
<br><br>
<a href="https://openreview.net/forum?id=QUYu0FMFXr">&ldquo;PluriHarms: Benchmarking the Full Spectrum of Human Judgments on AI Harm&rdquo;</a>. Jing-Jing Li, Joel Mire, Eve Fleisig, Valentina Pyatkin, Maarten Sap, Sydney Levine.
<br><br>
<a href="https://openreview.net/forum?id=7oTmEln6vo">&ldquo;LLM Agents Beyond Utility: An Open-Ended Perspective&rdquo;</a>. Asen Nachkov, Xi Wang, Luc Van Gool.
<br><br>
<a href="https://openreview.net/forum?id=IaQU3GH50K">&ldquo;Perceived vs. True Emergence: A Cognitive Account of Generalization in Clinical Time Series Models&rdquo;</a>. Shashank Yadav.
<br><br>
<a href="https://openreview.net/forum?id=PH26cSNsH4">&ldquo;A Neuroscience-Inspired Dual-Process Model of Compositional Generalization&rdquo;</a>. Alexander Noviello, Claas Beger, Jacob Groner, Kevin Ellis, Weinan Sun.
<br><br>
<a href="https://openreview.net/forum?id=5NxVmdeMMz">&ldquo;From Black Box to Bedside: Distilling Reinforcement Learning for Interpretable Sepsis Treatment&rdquo;</a>. Ella Lan, Andrea Yu, Sergio Charles.
<br><br>
<a href="https://openreview.net/forum?id=Q3iTP8Bl6X">&ldquo;Measuring LLM Generation Spaces with EigenScore&rdquo;</a>. Sunny Yu, Myra Cheng, Ahmad Jabbar, Robert D. Hawkins, Dan Jurafsky.
<br><br>
<a href="https://openreview.net/forum?id=WYUfI616Hp">&ldquo;Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding&rdquo;</a>. Vanessa Figueiredo.
<br><br>
<a href="https://openreview.net/forum?id=RJ7w9bEGTI">&ldquo;Causal Interventions on Continuous Features in LLMs: A Case Study in Verb Bias&rdquo;</a>. Zhenghao Zhou, R. Thomas McCoy, Robert Frank.
<br><br>
<a href="https://openreview.net/forum?id=0IcsigkJAS">&ldquo;Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behaviour&rdquo;</a>. Eric Zhang, Daniel Aarao Reis Arturi, Andrew Adrian Ansah, Kevin Zhu, Ashwinee Panda, Aishwarya Balwani.
<br><br>
<a href="https://openreview.net/forum?id=KKjt8VADoT">&ldquo;Reverse-Engineering Memory in DreamerV3: From Sparse Representations to Functional Circuits&rdquo;</a>. Jan Sobotka, Auke Ijspeert, Guillaume Bellegarda.
<br><br>
<a href="https://openreview.net/forum?id=MT9zaJoHjp">&ldquo;Does FLUX Know What It’s Writing?&quot;</a>. Adrian Chang, Sheridan Feucht, Byron C Wallace, David Bau.
<br><br>
<a href="https://openreview.net/forum?id=FIgoOA89K0">&ldquo;Discovering Functionally Sufficient Projections with Functional Component Analysis&rdquo;</a>. Satchel Grant.
<br><br>
<a href="https://openreview.net/forum?id=aq2MtJ320b">&ldquo;Towards Visual Simulation in Multimodal Language Models&rdquo;</a>. <a href="https://drive.google.com/file/d/1vM03VrPfDEyQkGFv-I01gvhATK9JJyMd/view?usp=sharing"> (Video Recording) </a> Catherine Finegan-Dollak.
<br><br>
<a href="https://openreview.net/forum?id=qgDo0ViaDT">&ldquo;RNNs reveal a new optimal stopping rule in sequential sampling for decision-making&rdquo;</a>. Jialin Li, Kenway Louie, Paul W. Glimcher, Bo Shen.
<br><br>
<a href="https://openreview.net/forum?id=srJFgAQ8fC">&ldquo;Minimization of Boolean Complexity in In-Context Concept Learning&rdquo;</a>. Leroy Z. Wang, R. Thomas McCoy, Shane Steinert-Threlkeld.
<br><br>
<a href="https://openreview.net/forum?id=ZSRaoVwb0R">&ldquo;Demystifying Emergent Exploration in Goal-conditioned RL&rdquo;</a>. Mahsa Bastankhah, Grace Liu, Dilip Arumugam, Thomas L. Griffiths, Benjamin Eysenbach.
<br><br>
<a href="https://openreview.net/forum?id=toaajUTyID">&ldquo;Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment&rdquo;</a>. María Victoria Carro, Denise Alejandra Mester, Francisca Gauna Selasco, Giovanni Franco Gabriel Marraffini, Mario Leiva, Gerardo Simari, Maria Vanina Martinez.
<br><br>
<a href="https://openreview.net/forum?id=6Bbuqennw0">&ldquo;How Do LLMs Ask Questions? A Pragmatic Comparison with Human Question-Asking&rdquo;</a>. Chani Jung, Jimin Mun, Xuhui Zhou, Alice Oh, Maarten Sap, Hyunwoo Kim.
<br><br>
<a href="https://openreview.net/forum?id=tkgxDkAVBv">&ldquo;Predicting the Formation of Induction Heads&rdquo;</a>. Tatsuya Aoyama, Ethan Wilcox, Nathan Schneider.
<br><br>
<a href="https://openreview.net/forum?id=F92Z5hsS11">&ldquo;How Intrinsic Motivation Shapes Learned Representations in Decision Transformers: A Cognitive Interpretability Analysis&rdquo;</a>. Leonardo Guiducci, Antonio Rizzo, Giovanna Maria Dimitri.
<br><br>
<a href="https://openreview.net/forum?id=7asnUDuVPR">&ldquo;Decoding and Reconstructing Visual Experience from Brain Activity with Generative Latent Representations&rdquo;</a>. Motokazu Umehara, Yoshihiro Nagano, Misato Tanaka, Yukiyasu Kamitani.
<br><br>
<a href="https://openreview.net/forum?id=eF2lcYSF0V">&ldquo;From Comparison to Composition: Towards Understanding Machine Cognition of Unseen Categories&rdquo;</a>. Minghao Fu, Sheng Zhang, Guangyi Chen, Zijian Li, Fan Feng, Yifan Shen, Shaoan Xie, Kun Zhang.
<br><br>
<a href="https://openreview.net/forum?id=HyfwJjytjB">&ldquo;Disentangling Interpretable Cognitive Variables That Support Human Generalization&rdquo;</a>. Xinyue Zhu, Daniel L. Kimmel.
<br><br>
<a href="https://openreview.net/forum?id=pjBVkyzwu8">&ldquo;Interpreting style–content parsing in vision–language models&rdquo;</a>. Fan L. Cheng, Xin Jing.
<br><br>
<a href="https://openreview.net/forum?id=S7r9LaYvdT">&ldquo;Acoustic Degradation Reweights Cortical and ASR  Processing: A Brain-Model Alignment Study&rdquo;</a>. Francis Pingfan Chien, Chia-Chun Dan Hsu, Po-Jang Hsieh, Yu Tsao.
<br><br>
<a href="https://openreview.net/forum?id=PNtwdoaihO">&ldquo;Towards Cognitively Plausible Concept Learning: Spatially Grounding Concepts with Anatomical Priors&rdquo;</a>. Yuyu Zhou.
<br><br>
<a href="https://openreview.net/forum?id=fd2Ssf8mMJ">&quot;(How) Do LLMs Plan in One Forward Pass?&quot;</a>. Michael Hanna, Emmanuel Ameisen.
<br><br>
<a href="https://openreview.net/forum?id=M9RFmHxrKM">&ldquo;Value Entanglement: Conflation Between Moral and Grammatical Good In (Some) Large Language Models&rdquo;</a>. Seong Hah Cho, Junyi Li, Anna Leshinskaya.
<br><br>
<a href="https://openreview.net/forum?id=6zzLOfIEnF">&ldquo;Stop Anthropomorphizing Intermediate Tokens as Reasoning/Thinking Traces!&quot;</a>. Subbarao Kambhampati, Kaya Stechly, Karthik Valmeekam, Lucas Paul Saldyt, Siddhant Bhambri, Vardhan Palod, Atharva Gundawar, Soumya Rani Samineni, Durgesh Kalwar, Upasana Biswas.
<br><br>
<a href="https://openreview.net/forum?id=apA1XvmQV3">&ldquo;Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?&quot;</a>. Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati.
<br><br>
<a href="https://openreview.net/forum?id=Ca6YfIpVBB">&ldquo;What is a Number, That a Large Language Model May Know It?&quot;</a>. Raja Marjieh, Veniamin Veselovsky, Thomas L. Griffiths, Ilia Sucholutsky.
<br><br>
<a href="https://openreview.net/forum?id=oB5MqHvEvL">&ldquo;NiceWebRL: a Python library for human subject experiments with reinforcement learning environments&rdquo;</a>. Wilka Carvalho, Vikram Srinivas Goddla, Ishaan Sinha, Hoon Shin, Kunal Jha.
<br><br>
<a href="https://openreview.net/forum?id=5kyIDVYrUv">&ldquo;The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends&rdquo;</a>. Nico Policzer, Cameron Braunstein, Mariya Toneva.
<br><br>
<a href="https://openreview.net/forum?id=iErDWmZD7y">&ldquo;Signatures of human-like processing in Transformer forward passes&rdquo;</a>. Jennifer Hu, Michael A. Lepori, Michael Franke.
<br><br>
<a href="https://openreview.net/forum?id=tRCsbjBIZ5">&ldquo;CurLL: Curriculum Learning of Language Models&rdquo;</a>. Pavan Kalyan Tankala, Shubhra Mishra, Satya Lokam, Navin Goyal.
<br><br>
<a href="https://openreview.net/forum?id=ZhJ6WPw0mp">&ldquo;Learning to Look: Cognitive Attention Alignment with Vision-Language Models&rdquo;</a>. Ryan L. Yang, Dipkamal Bhusal, Nidhi Rastogi.
<br><br>
<a href="https://openreview.net/forum?id=Ytm6dF43lP">&ldquo;Deconstructing the Reasoning Process of a Neuro-Fuzzy Agent: From Learned Concepts to Natural Language Narratives&rdquo;</a>. Yumin Zhou, Whye Loon Tung, Hiok Quek.
<br><br>
<a href="https://openreview.net/forum?id=4OdHkADJw9">&ldquo;A Cognitive Architecture for Probing Hierarchical Processing and Predictive Coding in Deep Vision Models&rdquo;</a>. Brennen Hill, Zhang Xinyu, Timothy Putra Prasetio.
<br><br>
<a href="https://openreview.net/forum?id=SDdpJUm4v7">&ldquo;Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence&rdquo;</a>. Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi.
<br><br>
<a href="https://openreview.net/forum?id=38yw6kthZW">&ldquo;Interpretable Traces, Unexpected Outcomes: Investigating the Disconnect in Trace-Based Knowledge Distillation&rdquo;</a>. Siddhant Bhambri, Upasana Biswas, Subbarao Kambhampati.
<br><br>
<a href="https://openreview.net/forum?id=0FhGN9j5xJ">&ldquo;MetaCD: A Meta Learning Framework for Cognitive Diagnosis based on Continual Learning&rdquo;</a>. Jin Wu, Chanjin Zheng.
<br><br></p>
</div>

    </section>
<div id="footer">
    Made with <a href="https://gohugo.io/">Hugo</a> and hosted on <a href="https://github.com/coginterp/neurips2025">GitHub</a>.
</div>


</body>

</html>